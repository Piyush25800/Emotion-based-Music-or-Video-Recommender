{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c482746-9a22-4906-916a-91ac027a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from fer import FER\n",
    "import webbrowser\n",
    "import random\n",
    "\n",
    "# ------------- CONFIG -------------\n",
    "\n",
    "# Emotion-wise YouTube playlists (change to your favourite links)\n",
    "PLAYLISTS = {\n",
    "    \"happy\": [\n",
    "        \"https://youtu.be/nJZcbidTutE?si=1kH9GbhD3NeIVUIr\",\n",
    "    ],\n",
    "    \"sad\": [\n",
    "        \"https://youtu.be/sVRwZEkXepg?si=clkpCbzrGtBb1eGv\",\n",
    "    ],\n",
    "    \"angry\": [\n",
    "        \"https://youtu.be/zqGW6x_5N0k?si=gkUTXcNSoreJo-_F\",\n",
    "    ],\n",
    "    \"neutral\": [\n",
    "        \"https://youtu.be/ITyHqStTDeg?si=7TwM3y_2IfODchZb\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Minimum confidence required to accept an emotion\n",
    "CONFIDENCE_THRESHOLD = 0.80\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "def map_raw_emotion_to_group(raw_emotion: str) -> str:\n",
    "    \"\"\"\n",
    "    FER emotions: angry, disgust, fear, happy, sad, surprise, neutral\n",
    "    We map them to 4 groups: happy, sad, angry, neutral.\n",
    "    \"\"\"\n",
    "    raw_emotion = raw_emotion.lower()\n",
    "\n",
    "    if raw_emotion == \"happy\":\n",
    "        return \"happy\"\n",
    "    if raw_emotion in [\"sad\", \"fear\"]:\n",
    "        return \"sad\"\n",
    "    if raw_emotion == \"angry\":\n",
    "        return \"angry\"\n",
    "    # disgust, surprise, neutral -> neutral\n",
    "    return \"neutral\"\n",
    "\n",
    "\n",
    "def pick_random_playlist_for_emotion(group_emotion: str) -> str:\n",
    "    if group_emotion not in PLAYLISTS or not PLAYLISTS[group_emotion]:\n",
    "        group_emotion = \"neutral\"\n",
    "    return random.choice(PLAYLISTS[group_emotion])\n",
    "\n",
    "\n",
    "def open_playlist(group_emotion: str):\n",
    "    url = pick_random_playlist_for_emotion(group_emotion)\n",
    "    print(f\"[ACTION] Opening {group_emotion} playlist: {url}\")\n",
    "    webbrowser.open(url)\n",
    "\n",
    "\n",
    "def main():\n",
    "    detector = FER(mtcnn=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    print(\"Instructions:\")\n",
    "    print(\"  - Camera window me apna face clearly dikhana\")\n",
    "    print(\"  - Light thodi bright rakho\")\n",
    "    print(\"  - Jab ready ho (expression set kar liya ho) to 'c' dabao\")\n",
    "    print(\"  - ESC dabao bina capture ke exit karne ke liye\\n\")\n",
    "\n",
    "    chosen_emotion = None\n",
    "    chosen_confidence = 0.0\n",
    "    chosen_group = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read from camera.\")\n",
    "            break\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (640, 480))\n",
    "        display_frame = frame_resized.copy()\n",
    "\n",
    "        cv2.putText(\n",
    "            display_frame,\n",
    "            \"Press 'c' to capture emotion, ESC to quit\",\n",
    "            (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            (0, 255, 255),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Emotion Capture\", display_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 27:  # ESC\n",
    "            print(\"Exiting without capturing emotion.\")\n",
    "            break\n",
    "\n",
    "        if key == ord('c'):  # capture emotion\n",
    "            # Take current frame and analyze\n",
    "            rgb_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "            result = detector.detect_emotions(rgb_frame)\n",
    "\n",
    "            if not result:\n",
    "                print(\"No face detected. Try again with your face closer/centered.\")\n",
    "                continue\n",
    "\n",
    "            face = result[0]\n",
    "            emotions_dict = face[\"emotions\"]\n",
    "            raw_emotion = max(emotions_dict, key=emotions_dict.get)\n",
    "            score = emotions_dict[raw_emotion]\n",
    "\n",
    "            print(f\"Detected raw emotion: {raw_emotion} (confidence={score:.2f})\")\n",
    "\n",
    "            if score < CONFIDENCE_THRESHOLD:\n",
    "                print(\"Confidence too low. Please try again with a clearer expression.\\n\")\n",
    "                continue\n",
    "\n",
    "            group_emotion = map_raw_emotion_to_group(raw_emotion)\n",
    "            chosen_emotion = raw_emotion\n",
    "            chosen_confidence = score\n",
    "            chosen_group = group_emotion\n",
    "            break\n",
    "\n",
    "    # Close camera & window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If we got a valid emotion, open playlist\n",
    "    if chosen_group is not None:\n",
    "        print(f\"\\nFinal Emotion: {chosen_emotion} (group: {chosen_group}, conf={chosen_confidence:.2f})\")\n",
    "        open_playlist(chosen_group)\n",
    "        print(\"Done. Program finished. ðŸ‘\")\n",
    "    else:\n",
    "        print(\"No valid emotion captured. No song played.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gestureenv)",
   "language": "python",
   "name": "gestureenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
